# Gestion utilisateurs et sécurité base

Sécuriser vos environnements IA en production

## Note importante

Les corrections des exercices pratiques de ce module sont disponibles dans le repository GitHub du cours mentionné dans le document d'introduction (0.1).

## Table des matières

1. [Utilisateurs et groupes](#utilisateurs-groupes)
2. [Permissions avancées](#permissions-avancees)
3. [Sécurité des projets IA](#securite-projets)
4. [Bonnes pratiques](#bonnes-pratiques)

## Utilisateurs et groupes

### Théorie : Modèle de sécurité Linux

Linux utilise un système de sécurité basé sur utilisateurs et groupes. En IA, cette gestion est cruciale pour protéger datasets sensibles, partager ressources d'équipe, et contrôler l'accès aux GPUs.

### Concepts fondamentaux

#### Identifiants système

| Concept | Description | Usage IA |
|---------|-------------|----------|
| **UID** | User ID numérique | Identification unique utilisateur |
| **GID** | Group ID numérique | Appartenance groupe |
| **Username** | Nom utilisateur | Interface humaine |
| **Primary group** | Groupe principal | Permissions par défaut |
| **Secondary groups** | Groupes secondaires | Accès ressources spécialisées |

#### Types d'utilisateurs

| Type | UID Range | Description | Usage IA |
|------|-----------|-------------|----------|
| **root** | 0 | Super-utilisateur | Administration système |
| **System** | 1-999 | Services système | Démons IA (jupyter, mlflow) |
| **Regular** | 1000+ | Utilisateurs normaux | Data scientists, développeurs |

### Gestion des utilisateurs

#### Commandes de base

| Commande | Description | Usage IA |
|----------|-------------|----------|
| **id** | Affiche UID/GID | Vérifier identité courante |
| **whoami** | Nom utilisateur actuel | Scripts d'identification |
| **groups** | Groupes de l'utilisateur | Vérifier permissions |
| **su - user** | Changer d'utilisateur | Test permissions |

#### Informations utilisateurs

**Fichiers système :**
- **/etc/passwd** : Base utilisateurs
- **/etc/group** : Définition groupes
- **/etc/shadow** : Mots de passe chiffrés
- **/etc/gshadow** : Mots de passe groupes

### Groupes spécialisés IA

#### Groupes système utiles

| Groupe | Description | Accès | Usage IA |
|--------|-------------|-------|----------|
| **docker** | Utilisateurs Docker | Docker daemon | Containers IA |
| **sudo** | Administrateurs | sudo access | Installation packages |
| **video** | Périphériques vidéo | GPU access | Accès GPU direct |
| **audio** | Périphériques audio | Audio devices | Projets speech/audio |

#### Groupes personnalisés

**Exemples organisationnels :**
- **ml-team** : Équipe machine learning
- **data-scientists** : Accès datasets
- **gpu-users** : Utilisateurs GPU
- **production** : Déploiement modèles

### Gestion des groupes

#### Administration groupes

**Bonnes pratiques :**
- Groupes par fonction/projet
- Permissions minimales nécessaires
- Révision régulière des appartenances
- Documentation des attributions

#### Partage ressources

**Stratégies efficaces :**
- Répertoires partagés par groupe
- Permissions groupes sur datasets
- Accès GPU par appartenance groupe
- Isolation projets sensibles

### Exemples pratiques

**Scénario : Organisation équipe IA**

Structure recommandée :
1. **Groupe ml-research** : Chercheurs, accès datasets publics
2. **Groupe ml-production** : DevOps, déploiement modèles
3. **Groupe data-admin** : Gestionnaires données, accès complet
4. **Groupe gpu-users** : Utilisateurs GPU, quotas ressources

### Pratique non corrigée

**Exercice 1 : Exploration identité**
- Identifiez vos UID/GID actuels
- Listez tous vos groupes
- Explorez les fichiers système /etc/passwd et /etc/group
- Comprenez votre position dans le système

**Exercice 2 : Simulation multi-utilisateurs**
- Créez structure de groupes pour projet IA
- Simulez différents rôles utilisateurs
- Testez accès selon appartenances groupes
- Documentez organisation recommandée

## Permissions avancées

### Théorie : Au-delà des permissions de base

Les projets IA nécessitent des permissions sophistiquées : accès partagé datasets, protection propriété intellectuelle, isolation environnements, contrôle ressources GPU.

### Permissions étendues

#### SetUID et SetGID

| Permission | Notation | Description | Usage IA |
|------------|----------|-------------|----------|
| **SetUID** | u+s (4xxx) | Exécution avec permissions propriétaire | Scripts privilégiés |
| **SetGID** | g+s (2xxx) | Exécution avec permissions groupe | Partage ressources équipe |
| **Sticky bit** | +t (1xxx) | Suppression limitée propriétaire | Répertoires partagés |

#### Applications IA

**Cas d'usage spécifiques :**
- **Répertoires datasets** : SetGID pour partage équipe
- **Scripts d'administration** : SetUID pour tâches privilégiées
- **Tmp partagés** : Sticky bit pour sécurité
- **Logs centralisés** : Permissions spécialisées

### ACL (Access Control Lists)

#### Permissions granulaires

**Avantages ACL :**
- Permissions par utilisateur spécifique
- Multiples groupes sur même ressource
- Permissions par défaut héritées
- Contrôle fin accès datasets

#### Commandes ACL

| Commande | Description | Usage IA |
|----------|-------------|----------|
| **getfacl file** | Afficher ACL | Audit permissions |
| **setfacl -m u:user:rwx file** | Modifier ACL | Accès spécifique |
| **setfacl -d -m g:group:rx dir** | ACL par défaut | Partage datasets |
| **setfacl -x u:user file** | Supprimer entrée | Révocation accès |

### Permissions spécialisées

#### Capabilities Linux

**Contrôle fin privilèges :**
- **CAP_NET_ADMIN** : Configuration réseau
- **CAP_SYS_ADMIN** : Administration système
- **CAP_DAC_OVERRIDE** : Bypass permissions fichiers
- **CAP_SYS_RESOURCE** : Limites ressources

#### Applications containers

**Sécurité containers IA :**
- Limitation capabilities par container
- Isolation ressources GPU
- Contrôle accès réseau
- Protection host system

### Chiffrement et protection

#### Chiffrement fichiers/répertoires

**Solutions disponibles :**
- **ecryptfs** : Chiffrement transparent
- **encfs** : Système fichiers chiffré
- **LUKS** : Chiffrement disque/partition
- **gpg** : Chiffrement fichiers individuels

#### Protection datasets sensibles

**Stratégies recommandées :**
- Chiffrement datasets personnels/médicaux
- Clés séparées des données
- Accès audit trail complet
- Sauvegarde sécurisée clés

### Exemples pratiques

**Scénario : Projet IA avec données médicales**

Sécurisation nécessaire :
1. **Chiffrement** : Datasets patients
2. **ACL** : Accès granulaire par rôle
3. **Audit** : Logging tous accès
4. **Isolation** : Environnements séparés
5. **Conformité** : Respect RGPD/HIPAA

### Monitoring sécurité

#### Audit d'accès

**Surveillance nécessaire :**
- Connexions utilisateurs système
- Accès fichiers sensibles
- Modifications permissions
- Tentatives accès non autorisé

#### Outils d'audit

| Outil | Fonction | Usage IA |
|-------|----------|----------|
| **auditd** | Audit système complet | Conformité réglementaire |
| **fail2ban** | Protection attaques | Sécurité SSH |
| **logwatch** | Analyse logs | Détection anomalies |
| **aide** | Intégrité fichiers | Détection modifications |

### Pratique non corrigée

**Exercice 3 : Permissions avancées**
- Expérimentez avec SetUID/SetGID
- Créez répertoires avec sticky bit
- Testez inheritance permissions
- Simulez environnement production

**Exercice 4 : ACL et granularité**
- Configurez ACL complexes sur datasets simulés
- Testez accès multiples utilisateurs/groupes
- Implémentez permissions par défaut
- Documentez structure d'accès

## Sécurité des projets IA

### Théorie : Spécificités sécuritaires IA

Les projets IA présentent des risques spécifiques : datasets sensibles, modèles propriétaires, compute coûteux, compliance réglementaire. La sécurité doit être intégrée dès la conception.

### Sécurisation datasets

#### Classification données

| Niveau | Description | Mesures | Exemple IA |
|--------|-------------|---------|------------|
| **Public** | Données ouvertes | Permissions standard | Datasets ImageNet |
| **Internal** | Usage interne | Accès employés | Données ventes |
| **Confidential** | Données sensibles | Accès restreint | Stratégie produit |
| **Restricted** | Très sensibles | Chiffrement + audit | Données médicales |

#### Protection par niveau

**Mesures graduées :**
- **Public** : Backup et intégrité
- **Internal** : Contrôle accès + logs
- **Confidential** : Chiffrement + ACL strictes
- **Restricted** : Chiffrement + audit complet + air gap

### Sécurité modèles

#### Protection propriété intellectuelle

**Risques spécifiques :**
- Vol algorithmes propriétaires
- Extraction paramètres modèles
- Reverse engineering architectures
- Fuite données d'entraînement

#### Mesures protection

**Stratégies défensives :**
- Chiffrement modèles au repos
- Contrôle accès API inference
- Watermarking modèles
- Monitoring usage anormal

### Isolation environnements

#### Séparation par projet

**Niveaux isolation :**
- **Utilisateurs** : Comptes séparés par projet
- **Groupes** : Permissions par équipe
- **Containers** : Isolation runtime
- **VMs** : Isolation complète

#### Gestion ressources

**Contrôle accès GPU :**
- Quotas par utilisateur/groupe
- Scheduling prioritaire
- Monitoring utilisation
- Billing interne

### Conformité réglementaire

#### Standards applicables

| Réglementation | Domaine | Impact IA |
|----------------|---------|-----------|
| **RGPD** | Données personnelles EU | Datasets clients |
| **HIPAA** | Données médicales US | IA santé |
| **SOX** | Finance US | IA trading/risque |
| **ISO 27001** | Sécurité information | Gouvernance globale |

#### Exigences techniques

**Implémentations nécessaires :**
- Audit trails complets
- Chiffrement bout-en-bout
- Anonymisation/pseudonymisation
- Droit à l'oubli technique

### Exemples pratiques

**Scénario : Startup IA Healthcare**

Architecture sécurisée :
1. **Zone DMZ** : APIs publiques
2. **Zone interne** : Développement/test
3. **Zone sécurisée** : Données patients
4. **Zone isolée** : Entraînement modèles
5. **Vault** : Clés et secrets

### Incident response

#### Plan de réponse

**Procédures essentielles :**
- Détection incident sécuritaire
- Isolation système compromis
- Investigation et forensics
- Remediation et récupération
- Post-mortem et amélioration

#### Outils de réponse

**Capacités nécessaires :**
- Monitoring temps réel
- Alertes automatiques
- Isolation réseau rapide
- Backup/restore sécurisé
- Communication crise

### Pratique non corrigée

**Exercice 5 : Classification et protection**
- Classifiez des datasets selon sensibilité
- Implémentez mesures protection appropriées
- Testez contrôles d'accès
- Documentez procédures sécurité

**Exercice 6 : Simulation incident**
- Créez scénario compromission
- Appliquez procédures réponse
- Testez capacités investigation
- Améliorez défenses

## Bonnes pratiques

### Théorie : Sécurité opérationnelle

La sécurité IA ne se limite pas aux mesures techniques. Elle inclut processus, formation, culture sécurité, et amélioration continue. L'objectif est un équilibre sécurité/productivité optimal.

### Principe moindre privilège

#### Application pratique

**Règles d'or :**
- Accès minimal nécessaire
- Révision régulière permissions
- Rotation des accès privilégiés
- Justification documentée

#### Gestion des accès

**Processus recommandés :**
- Demande d'accès formalisée
- Approbation hiérarchique
- Provisioning automatisé
- Dé-provisioning au départ

### Gestion des secrets

#### Types de secrets IA

| Type | Exemples | Stockage | Rotation |
|------|----------|----------|----------|
| **API Keys** | OpenAI, AWS | Vault sécurisé | Mensuelle |
| **DB Passwords** | PostgreSQL, MongoDB | Chiffré | Trimestrielle |
| **SSH Keys** | Accès serveurs | Agent SSH | Annuelle |
| **Certificates** | TLS, signatures | PKI | Selon expiration |

#### Solutions de gestion

**Outils recommandés :**
- **HashiCorp Vault** : Gestion centralisée
- **AWS Secrets Manager** : Cloud AWS
- **Azure Key Vault** : Cloud Azure
- **pass** : Solution simple locale

### Monitoring et alertes

#### Métriques sécurité

**Indicateurs clés :**
- Tentatives connexion échouées
- Accès fichiers sensibles
- Modifications permissions
- Usage ressources anormal
- Transferts données volumineux

#### Système d'alertes

**Niveaux d'alerte :**
- **INFO** : Événements normaux
- **WARNING** : Situations suspectes
- **CRITICAL** : Incidents sécurité
- **EMERGENCY** : Compromission confirmée

### Formation et sensibilisation

#### Programme formation

**Sujets essentiels :**
- Bonnes pratiques mots de passe
- Gestion des accès et permissions
- Reconnaissance social engineering
- Procédures incident sécurité
- Conformité réglementaire

#### Culture sécurité

**Éléments clés :**
- Responsabilité partagée
- Communication ouverte incidents
- Amélioration continue
- Reconnaissance bonnes pratiques

### Documentation et procédures

#### Documentation essentielle

**Documents requis :**
- Politique sécurité générale
- Procédures d'accès
- Plan de réponse incident
- Guides utilisateurs
- Architecture sécurité

#### Révision et mise à jour

**Processus continu :**
- Révision annuelle politiques
- Mise à jour post-incident
- Adaptation nouvelles menaces
- Formation équipes

### Exemples pratiques

**Scénario : Mise en place gouvernance sécurité IA**

Programme complet :
1. **Assessment** : Audit sécurité actuelle
2. **Policies** : Création politiques adaptées
3. **Implementation** : Déploiement mesures techniques
4. **Training** : Formation équipes
5. **Monitoring** : Surveillance continue
6. **Improvement** : Amélioration basée retours

### Automatisation sécurité

#### Security as Code

**Approches modernes :**
- Infrastructure as Code sécurisée
- Tests sécurité automatisés
- Déploiement avec contrôles
- Monitoring intégré CI/CD

#### DevSecOps pour IA

**Intégration sécurité :**
- Scanning vulnérabilités containers
- Tests sécurité modèles IA
- Validation datasets compliance
- Monitoring runtime sécurité

### Pratique non corrigée

**Exercice 7 : Politique sécurité**
- Rédigez politique sécurité pour projet IA
- Définissez procédures d'accès
- Créez guide utilisateurs
- Testez application pratique

**Exercice 8 : Monitoring sécurité**
- Configurez monitoring événements sécurité
- Implémentez alertes automatiques
- Testez réponse aux incidents
- Documentez leçons apprises

**Exercice 9 : Programme complet**
- Concevez programme sécurité IA complet
- Intégrez formation et sensibilisation
- Planifiez amélioration continue
- Présentez à équipe fictive

## Conclusion

### Points clés à retenir

- **Utilisateurs/Groupes** : Organisation sécurisée par rôles et responsabilités
- **Permissions** : Contrôle granulaire avec ACL et capabilities
- **Projets IA** : Sécurisation spécifique datasets et modèles
- **Bonnes pratiques** : Culture sécurité et amélioration continue

### Compétences acquises

Après ce module, vous devriez être capable de :
- Gérer utilisateurs et groupes pour projets IA sécurisés
- Implémenter permissions avancées et contrôles d'accès
- Sécuriser datasets sensibles et modèles propriétaires
- Développer et maintenir programme sécurité IA complet

### Prochaines étapes

Vous avez maintenant une base solide en Linux pour l'IA. Les modules suivants couvriront des sujets plus avancés comme la containerisation, l'orchestration, et le déploiement de solutions IA en production.
